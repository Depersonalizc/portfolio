<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="icon" href="./assets/favicon.png">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/css/bootstrap.min.css" integrity="sha384-rbsA2VBKQhggwzxH7pPCaAqO46MgnOM80zW1RWuH61DGLwZJEdK2Kadq2F9CUG65" crossorigin="anonymous">
    <link rel="stylesheet" href="./css/style.css">
    <title>Volumetric Clouds</title>

</head>
<body>
    <nav>
        <div class="nav-row mb-3">
            <h1><a class="link-logo" href="index.html">Jamie Chen</a></h1>
            <div class="nav-contact">
                <a href="https://github.com/Depersonalizc/" target="_blank"><div><img class="icon" src="./assets/icon/github.svg"></div></a>
                <a href="https://www.linkedin.com/in/angjchen/" target="_blank"><div><img class="icon" src="./assets/icon/linkedin.svg"></div></a>
                <a href="mailto:ang_chen@brown.edu"><div><img class="icon" src="./assets/icon/email.svg"></div></a>
                <a href="index.html" target="_blank"><div><img class="icon" src="./assets/icon/cv.svg"></div></a>
            </div>
            
        </div>
        <div class="nav-row">
            <div class="nav-words pr-1">
                <p class="nav-p">Aspiring software engineer, UI/UX apprentice.</p>
                <p class="nav-p">I love building stuff with code & all things visual computing!</p>    
            </div>
            <div class="nav-options">
                <a href="index.html" style="color: #F25D5D"><span>projects</span></a>
                <a href="about.html"><span>about</span></a>
            </div>
        </div>
    </nav>

    <main class="project-page" id="project-clouds">
        <div class="side-bar">
            <a class="mono-link" href="#project-clouds"><div class="title">Volumetric Clouds</div></a>
            <div class="tags">
                Graphics  ·  OpenGL  ·  C++
            </div>
            <div class="desc">Building a real-time volumetric clouds renderer with OpenGL.</div>
        </div>
        <div class="main-text">
            <div class="hidden-sm">
                <a class="mono-link" href="#project-clouds"><h2 class="m-0">Volumetric Clouds</h2></a>
                <div class="tags" style="width: 100%;">
                    Graphics  ·  OpenGL  ·  C++
                </div>
                <div class="desc">Building a real-time volumetric clouds renderer with OpenGL.</div>
                </div>
            <video class="showcase-img" controls=""
            src="assets/img/clouds/showcase.mp4"></video>

            <p>
                <a href="https://github.com/Depersonalizc/volumetric-clouds" target="_blank" class="project-link github-link">
                    <strong>Github</strong>
                </a>
              </p>

            <p>
                I really like clouds. That's why I built a real-time volumetric clouds renderer with my <a href="https://cs1230.graphics/">computer graphics</a> teammates, based on 
                <a href="http://killzone.dl.playstation.net/killzone/horizonzerodawn/presentations/Siggraph15_Schneider_Real-Time_Volumetric_Cloudscapes_of_Horizon_Zero_Dawn.pdf">
                this</a> talk at SIGGRAPH 2015 from the development team of <em>Horizon Zero Dawn</em>. The renderer we developed with OpenGL and C++ features intricate cloud <a href="#shape">shapes 
                generation</a>, realistic <a href="#lighting"> lighting effects</a>, and a physically-based <a href="#sky">sky</a> that varies throughout the day.
            </p>
        
            
            <a class="mono-link" href="#shape"><h2 id="shape">I. Shape</h2></a>
            <p><a href="https://en.wikipedia.org/wiki/Worley_noise">Worley noise</a> is a type of cellular noise where the value of each point 
                in space is determined by its distance to the closest neighbor in a set of random feature points. It is great for 
                modeling the density of clouds because when inverted (hover or tap on the image below to see it yourself!), it produces those nice bobbly patterns that resemble clouds.
            </p>
            <div class="img-hover-pair">
                <img src="./assets/img/clouds/worley.png"></img>
                <img src="./assets/img/clouds/worley_inverted.png"></img>
            </div>
            <a class="mono-link" href="#generating-worley-fast"><h3 id="generating-worley-fast">Generating Worley Noise, Fast</h3></a>
            <p>
                The first optimization we make of the above process is to take stratified samples of feature points in regular grid cells (let's call them
                grid points) instead of uniformly in space. 
                This reduces the quadratic number of candidate neighbors dramatically to 27 (constant!) in 3D since we can easily find the cell
                any point belongs. Here is an illustration for the 2D case as it is slightly easier to draw.
            </p>
            <img src="./assets/img/clouds/stratified.jpg" class="mix-multiply"></img>
            <p>
                For even greater efficiency, we write a compute shader and feed all the grid points to it. The compute shader can then 
                calculate a 3D noise map with hundreds of GPU cores in parallel. Long live parallelism!
            </p>
            <a class="mono-link" href="#fractal-noise"><h3 id="fractal-noise">Fractal Noise</h3></a>
            <p>
                To create sufficient details for our clouds, we generate two sets of 3D Worley noise texture: a high resolution (200x200x200) one
                that controls the overall shape of the clouds, and a second lower resolution (64x64x64) one that adds details to the base
                shape by eroding lower-density regions of the shape texture. Each texture map has 4 channels of 3-layer Worley noise of 
                increasing frequency. This overlaying process generates <a href="https://thebookofshaders.com/13/">fractal-like</a> noise 
                textures that add great details to our clouds. Below are slices of the four channels of our high resolution shape texture.
            </p>
            <div class="grid-2x2">
                <img src="./assets/img/clouds/r2.png" alt="Worley noise channel R">
                <img src="./assets/img/clouds/g2.png" alt="Worley noise channel G">
                <img src="./assets/img/clouds/b2.png" alt="Worley noise channel B">
                <img src="./assets/img/clouds/a2.png" alt="Worley noise channel A">
            </div>
  
            <a class="mono-link" href="#tileable"><h3 id="tileable">Making it Tileable</h3></a>
            <p>
                One last pitfall of our previous scheme is that textures created that way are not tileable: visible seams appear when we place two copies of a
                texture next to each other. Luckily, there's a simple trick to fix that: wrap the grid points around the unit cube. This makes
                the grid points periodic and thus makes the noise texture tileable as well.
            </p>
    
            
            <a class="mono-link" href="#lighting"><h2 id="lighting">II. Lighting</h2></a>
            <p>We implemented the following two components for fast, realistic lighting for clouds.</p>
            <ul>
                <li><a href="#beers-law">Beer's Law</a> or the exponential decay of light</li>
                <li><a href="#anistropic-scattering">Anistropic scattering</a> responsible for the iconic silver lining effect</li>
            </ul>
            <a class="mono-link" href="#beers-law"><h3 id="beers-law">Beer's Law</h3></a>
            <p>
                Beer's Law models the exponential decay of light energy as it propagates in an attenuating medium, like clouds. 
                In a uniform medium, the energy of light attenutaes in a simple exponential function of the distance travelled.
            </p>
            <img src="./assets/img/clouds/eq/eq_beer.svg" class="eq-block" style="height: 1.39rem;">
            <p>
                For light travelling through a heterogeneous medium, we can modify the equation above slightly to acount for the varying medium density.
            </p>
            <img src="./assets/img/clouds/eq/eq_beer_hetero.svg" class="eq-block" style="height: 1.8rem">
            This type of attenuation can be found at multiple spots in the volume rendering equation.
            <img src="./assets/img/clouds/eq/eq_volume.svg" class="eq-block" style="height: 4.0rem">
            <img src="./assets/img/clouds/volume.jpeg" alt="Diagram showing different terms in the volume rendering equation." class="mix-multiply">
            <p>
                Implementing the equation in code that runs in real time, however, means that we have to make several approximations. 
                Since a closed-form solution is clearly not feasible, we need to resort to Monte-Carlo integration instead. 
                That means taking mutiple samples along a ray and doing discrete sums of light energy and transmittance.
            </p>
            <p>
                The obvious headache now is the in-scattering term C. (We can ignore emssion since clouds don't shine themselves.) Evaulating it
                precisely involves taking an integral of all in-scattered light over all possible direction - but each beam of in-scattered light obeys
                the exact same formula we are trying to solve! Instead of fighting this recursive nightmare, we make the assumption that
                most of the in-scattered energy comes from the primary scattering path: Sun → volume → sample point. This simplifies the in-scattering 
                down to just one integral
            </p>
            <img src="./assets/img/clouds/eq/eq_inscatter.svg" class="eq-block" style="height: 2rem">
            <p>This is now much more computationally tractable and it gives us a base lighting model to build upon.</p>
            <img src="./assets/img/clouds/render-beers.png" alt="Clouds rendered with Beer's Law." class="mix-multiply">


            <a class="mono-link" href="#anistropic-scattering"><h3 id="anistropic-scattering">Anistropic Scattering</h3></a>
            <p>
                Anistropic scattering may sound like a scary term. But it really just means that light prefers to scatter in some direction 
                rather than others. In clouds, light tends to scatter forward instead of backward. This is what gives clouds the silver 
                lining look when the Sun shines right through them.
            </p>
            <p>
                Following the SIGGRAPH talk, we use the Henyey-Greenstein phase function, 
                originally proposed in 1949 for modeling diffusion of light in galaxies, to produce the anisotropy in cloud lighting.
            </p>
            <img src="./assets/img/clouds/eq/eq_hg.svg" class="eq-block" style="height: 3rem">
            <p>Adding the Henyey-Greenstein phase function to Beer's Law gives us the following nice result.</p>
            <img src="./assets/img/clouds/render-hg.png" alt="Clouds render with Beer's law and Henyey-Greenstein phase function." class="mix-multiply">
            <p>Notice how much brighter the cloud has become near the sun. We just got our silver lining!</p>

            <!-- <a class="mono-link" href="#dark-edges"><h3 id="dark-edges">Dark Edges</h3></a>
            <p style="margin-bottom: 0;">
                There's still one ingredient missing from our cloud lighting - the dark edges on the clouds when we look away 
                from the Sun. In the SIGGRAPH talk, this effect was referred to as the "powdered sugar look" because there seems to be a similar effect 
                in piles of powdered sugar.
            </p>
            <div class="row">
                <div class="col-6"><img src="./assets/img/clouds/powder-clouds.png"></div>
                <div class="col-6"><img src="./assets/img/clouds/powder-sugar.png"></div>
            </div>
            <p>
                The reason we do not get this effect automatically is due to our crude, one-bounce scattering approximation. In reality, 
                the chance of in-scattering is much more significant as we go deeper in a cloud, since scatterd light is more likely 
                to escape closer to the cloud surface. To approximate this effect, we can multiply each light energy sample by a correction 
                term that grows with the depth from the cloud surface.
            </p>
            <img src="./assets/img/clouds/eq/eq_powder.svg" class="eq-block" style="height: 3rem">

            <p>
                <em>coming soon...</em>
            </p>                 -->
            <a class="mono-link" href="#sky"><h2 id="sky">III. Sky</h2></a>
            <em>Coming soon...</em>
        </div>
    </main>

    <footer>
        Made with 🍦 by Jamie Chen © 2022.
    </footer>
            

</body>
</html>
